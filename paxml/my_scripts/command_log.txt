# 启动ray server
gcloud compute tpus tpu-vm ssh llm-jax-v3-32 --zone=us-east1-d --worker=0 --command="/home/lishengping/miniconda3/bin/ray start --head --port=3333 --resources='{\"tpu\": 1}'"  --project=llm-tpu
# vpn
sudo apt-get update && apt-get dist-upgrade
wget https://git.io/vpnsetup -O vpnsetup.sh && sudo \
VPN_IPSEC_PSK='lisen' \
VPN_USER='lisen' \
VPN_PASSWORD='lisen' sh vpnsetup.sh

重启服务
sudo service ipsec restart && sudo service xl2tpd restart

查看连接客户端
sudo ipsec whack --trafficstatus

查看连接日志
tail -F /var/log/auth.log | grep pluto

查看服务状态
sudo ipsec status
sudo ipsec verify

sudo iptables -A INPUT -p tcp --dport 12345 -j ACCEPT
sudo iptables -A OUTPUT -p tcp --sport 12345 -j ACCEPT


TPU_NAME=llm-jax-v4-32-10
ZONE=us-central2-b
STEP=0
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b main https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis"
MODEL_SIZE=14B
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="sudo apt-get install golang; /home/lishengping/miniconda3/bin/pip install jax-smi"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; sudo rm -f /tmp/libtpu_lockfile;sudo chmod +777 -R /tmp/tpu_logs/; /home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen$MODEL_SIZE --job_log_dir=gs://llm_base_models/qwen/$MODEL_SIZE/test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False| tee Qwen$MODEL_SIZE.step$STEP.log"

MODEL_SIZE=14B
python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen$MODEL_SIZE --job_log_dir=gs://llm_base_models/qwen/$MODEL_SIZE/test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False| tee Qwen$MODEL_SIZE.log


TPU_NAME=llm-jax-v3-128-10
ZONE=us-east1-d
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="grep model_dir Qwen14B.stepdebugif0.log"

TPU_NAME=llm-jax-v3-128-10
ZONE=us-east1-d
MODEL_SIZE=14B
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b main https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; /home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen$MODEL_SIZE --job_log_dir=gs://llm_base_models/qwen/$MODEL_SIZE/paxml1208/ 2>&1 --enable_checkpoint_saving=True --eval_on_test=True| tee Qwen$MODEL_SIZE.log"


gcloud compute tpus tpu-vm scp t_c4.py $TPU_NAME:/home/lishengping/projects/paxml/paxml/tasks/lm/params/c4.py  --zone=$ZONE  --worker=all  --project=llm-tpu

SIZE=12b
EXP=Pythia12BFlanMiniEval
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9;killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/pythia/pythia-$SIZE-paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True --eval_model_step=$STEP| tee $EXP.step$STEP.log"


MODEL_SIZE=14B
STEP=0
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; /home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen$MODEL_SIZE --job_log_dir=gs://llm_base_models/qwen/$MODEL_SIZE/paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True| tee Qwen$MODEL_SIZE.step$STEP.log"

# kill
gcloud compute tpus tpu-vm ssh llm-jax-v3-32-10 --zone=us-east1-d --worker=all --command="sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9"


# v4 PilePythia7B256x1DynWFFN16HD128Win256Alignedv4
TPU_NAME=llm-jax-v3-8-10
ZONE=us-east1-d
STEP=3000
EXP=PilePythia7B256x1DynWFFN16HD128Win256AlignedPileEval
gcloud compute tpus tpu-vm ssh $TPU_NAME  --project=llm-tpu --worker all  --zone $ZONE --command="cd /home/lishengping/;sudo rm -r projects/*; cd projects; git clone -b xd/dev https://github.com/xiaoda99/paxml.git;git clone -b xd/dev https://github.com/xiaoda99/praxis.git"
gcloud compute tpus tpu-vm scp models.py embedding_softmax.py $TPU_NAME:/home/lishengping/projects/praxis/praxis/layers/ --zone=$ZONE  --worker=all  --project=llm-tpu
gcloud compute tpus tpu-vm scp model_params.py  $TPU_NAME:/home/lishengping/projects/paxml/paxml/tasks/lm/ --zone=$ZONE  --worker=all  --project=llm-tpu
gcloud compute tpus tpu-vm scp executors.py main.py checkpoint_creators.py $TPU_NAME:/home/lishengping/projects/paxml/paxml/ --zone=$ZONE  --worker=all  --project=llm-tpu
gcloud compute tpus tpu-vm scp c4.py $TPU_NAME:/home/lishengping/projects/paxml/paxml/tasks/lm/params/c4.py  --zone=$ZONE  --worker=all  --project=llm-tpu

gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_projects_us-central2/log/PilePythia7B256x1DynWFFN16HD128Win256Alignedv4/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True| tee $EXP.Step$STEP.log"


# v4 PilePythia7B256x1DynWFFN16HD128Win256Alignedv4
TPU_NAME=llm-jax-v4-32-10
ZONE=us-central2-b
STEP=33000
gcloud compute tpus tpu-vm ssh $TPU_NAME  --project=llm-tpu --worker all  --zone $ZONE --command="cd /home/lishengping/;sudo rm -r projects/*; cd projects; git clone -b xd/dev https://github.com/xiaoda99/paxml.git;git clone -b xd/dev https://github.com/xiaoda99/praxis.git"
gcloud compute tpus tpu-vm scp c4.py $TPU_NAME:/home/lishengping/projects/paxml/paxml/tasks/lm/params/c4.py  --zone=$ZONE  --worker=all  --project=llm-tpu

Cleaning up existing temporary directories at gs://llm_projects_us-central2/log/PilePythia7B256x1DynWFFN16HD128Win256Alignedv4/checkpoints.


Pile v4-16-10  2.8B
TPU_NAME=llm-jax-v4-16-10
STEP=143000
ZONE=us-central2-b
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b pythia https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Pythia2p8BFlanMiniEval --job_log_dir=gs://llm_base_models/pythia/pythia-2.8b-paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True| tee Pythia2p8BFlanMiniEval.Step$STEP.log"



Pile v3-64-10  7B
TPU_NAME=llm-jax-v3-64-10
ZONE=us-east1-d
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b pythia https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis;killall main.py"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Pythia7BPileEval --job_log_dir=gs://llm_base_models/pythia/pythia-6.9b-paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True| tee Pythia7BPileEval.Step$STEP.log"

Pile v3-64-13  12B-2
TPU_NAME=llm-jax-v3-64-10
STEP=33000
ZONE=us-east1-d
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b pythia https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis;killall main.py"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Pythia12BPileEval --job_log_dir=gs://llm_base_models/pythia/pythia-12b-paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True| tee Pythia12BPileEval.Step$STEP.log"


FlanMini v3-32-10  7B
TPU_NAME=llm-jax-v3-32-10
STEP=23000
ZONE=us-east1-d
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b pythia https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis;killall main.py"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Pythia7BFlanMiniEval --job_log_dir=gs://llm_base_models/pythia/pythia-6.9b-paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True --eva_model_step=$STEP| tee Pythia7BFlanMiniEval.step$STEP.log"


FlanMini v3-64-11  12B
TPU_NAME=llm-jax-v3-64-10
STEP=3000
ZONE=us-east1-d
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b pythia https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis;killall main.py"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Pythia12BFlanMiniEval --job_log_dir=gs://llm_base_models/pythia/pythia-6.9b-paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True| tee Pythia12BFlanMiniEval.Step$STEP.log"

# qwen-7b
python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen7B --job_log_dir=gs://llm_base_models/qwen/7b/paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False| tee Qwen7B.log

 
33000, 12b pile float32
eval_metrics: [{'aux_loss': 0.0, 'avg_xent': 2.0879445, 'fraction_of_correct_next_step_preds': 0.5645174, 'log_pplx': 2.0879445, 'num_predictions': 2095831.8, 'total_loss': 2.0879445}]
I1121 13:56:41.942080 140600586442752 executors.py:373] write_json: {'aux_loss': '0.0', 'avg_xent': '2.0879445', 'fraction_of_correct_next_step_preds': '0.5645174', 'log_pplx': '2.0879445', 'num_predictions': '2095831.8', 'total_loss': '2.0879445'}
I1121 13:56:41.942376 140600586442752 executors.py:376] eval_result_path: gs://llm_base_models/pythia/pythia-6.9b-paxml/eval_metrics.Pile.train.33000.json


14300 7b flan flaot32
Wrote summary entry at step `143000` (loss=`3.264148`).
I1121 14:09:22.082455 140504437872640 programs.py:690] Writing eval outputs to gs://llm_base_models/pythia/pythia-6.9b-paxml/eval_out/FlanMini.test/eval_out_143000_shard_0 with 163840 entries
I1121 14:10:01.762053 140504437872640 executors.py:370] eval_metrics: [{'aux_loss': 0.0, 'avg_xent': 3.2624993, 'fraction_of_correct_next_step_preds': 0.4234591, 'log_pplx': 3.2624993, 'num_predictions': 25956.637, 'total_loss': 3.2624993}]
I1121 14:10:01.762461 140504437872640 executors.py:373] write_json: {'aux_loss': '0.0', 'avg_xent': '3.2624993', 'fraction_of_correct_next_step_preds': '0.4234591', 'log_pplx': '3.2624993', 'num_predictions': '25956.637', 'total_loss': '3.2624993'}
I1121 14:10:01.762703 140504437872640 executors.py:376] eval_result_path: gs://llm_base_models/pythia/pythia-6.9b-paxml/eval_metrics.FlanMini.train.143000.json


14300 12b pile flaot32
total_loss=1.794458 (weight=339524800.000000)
I1121 14:38:21.221881 140308956825600 local.py:45] Setting task status: step = 143000, loss= 1.7944560050964355, aux_loss=0.0, avg_xent=1.794458270072937, fraction_of_correct_next_step_preds=0.6059816479682922, log_pplx=1.794458270072937, num_predictions=2095832.25, total_loss=1.794458270072937
I1121 14:38:21.244586 140308956825600 summary_utils.py:448] Wrote summary entry at step `143000` (loss=`1.794456`).
I1121 14:38:21.347818 140308956825600 executors.py:370] eval_metrics: [{'aux_loss': 0.0, 'avg_xent': 1.7944595, 'fraction_of_correct_next_step_preds': 0.6059815, 'log_pplx': 1.7944595, 'num_predictions': 2095831.8, 'total_loss': 1.7944595}]
I1121 14:38:21.347944 140308956825600 executors.py:373] write_json: {'aux_loss': '0.0', 'avg_xent': '1.7944595', 'fraction_of_correct_next_step_preds': '0.6059815', 'log_pplx': '1.7944595', 'num_predictions': '2095831.8', 'total_loss': '1.7944595'}
I1121 14:38:21.348038 140308956825600 executors.py:376] eval_result_path: gs://llm_base_models/pythia/pythia-12b-paxml/eval_metrics.Pile.train.143000.json


33000 12b pile flaot32
summary_utils.py:448] Wrote summary entry at step `33000` (loss=`1.968474`).
I1121 15:53:50.234416 140410682583040 programs.py:690] Writing eval outputs to gs://llm_base_models/pythia/pythia-12b-paxml/eval_out/Pile.test/eval_out_33000_shard_0 with 165888 entries
I1121 15:54:51.297042 140410682583040 executors.py:370] eval_metrics: [{'aux_loss': 0.0, 'avg_xent': 1.9684777, 'fraction_of_correct_next_step_preds': 0.5774783, 'log_pplx': 1.9684777, 'num_predictions': 2095831.8, 'total_loss': 1.9684777}]
I1121 15:54:51.297456 140410682583040 executors.py:373] write_json: {'aux_loss': '0.0', 'avg_xent': '1.9684777', 'fraction_of_correct_next_step_preds': '0.5774783', 'log_pplx': '1.9684777', 'num_predictions': '2095831.8', 'total_loss': '1.9684777'}
I1121 15:54:51.297706 140410682583040 executors.py:376] eval_result_path: gs://llm_base_models/pythia/pythia-12b-paxml/eval_metrics.Pile.train.33000.json


14300 7b pile flaot32 wu pad loss
I1122 03:24:22.743440 140718536423424 local.py:45] Setting task status: step = 143000, loss= 1.8395969867706299, aux_loss=0.0, avg_xent=1.8395992517471313, fraction_of_correct_next_step_preds=0.5991172194480896, log_pplx=1.8395992517471313, num_predictions=2095832.25, total_loss=1.8395992517471313
I1122 03:24:23.866902 140718536423424 summary_utils.py:448] Wrote summary entry at step `143000` (loss=`1.839597`).
I1122 03:24:23.925146 140718536423424 programs.py:690] Writing eval outputs to gs://llm_base_models/pythia/pythia-6.9b-paxml/eval_out/Pile.test/eval_out_143000_shard_0 with 165888 entries
I1122 03:25:26.631429 140718536423424 executors.py:370] eval_metrics: [{'aux_loss': 0.0, 'avg_xent': 1.8396003, 'fraction_of_correct_next_step_preds': 0.59911704, 'log_pplx': 1.8396003, 'num_predictions': 2095831.8, 'total_loss': 1.8396003}]
I1122 03:25:26.631811 140718536423424 executors.py:373] write_json: {'aux_loss': '0.0', 'avg_xent': '1.8396003', 'fraction_of_correct_next_step_preds': '0.59911704', 'log_pplx': '1.8396003', 'num_predictions': '2095831.8', 'total_loss': '1.8396003'}
I1122 03:25:26.632023 140718536423424 executors.py:376] eval_result_path: gs://llm_base_models/pythia/pythia-6.9b-paxml/eval_metrics.Pile.train.143000.json


3000 7b pile flaot32
57.738480 139846637156352 summary_utils.py:448] Wrote summary entry at step `3000` (loss=`2.577582`).
I1122 05:00:57.797963 139846637156352 programs.py:690] Writing eval outputs to gs://llm_base_models/pythia/pythia-6.9b-paxml/eval_out/Pile.test/eval_out_3000_shard_0 with 165888 entries
I1122 05:01:59.520355 139846637156352 executors.py:370] eval_metrics: [{'aux_loss': 0.0, 'avg_xent': 2.5775824, 'fraction_of_correct_next_step_preds': 0.4972553, 'log_pplx': 2.5775824, 'num_predictions': 2097152.0, 'total_loss': 2.5775824}]
I1122 05:01:59.520754 139846637156352 executors.py:373] write_json: {'aux_loss': '0.0', 'avg_xent': '2.5775824', 'fraction_of_correct_next_step_preds': '0.4972553', 'log_pplx': '2.5775824', 'num_predictions': '2097152.0', 'total_loss': '2.5775824'}
I1122 05:01:59.520973 139846637156352 executors.py:376] eval_result_path: gs://llm_base_models/pythia/pythia-6.9b-paxml/eval_metrics.Pile.train.3000.json
is_training: True


TFDS_DATA_DIR=gs://jax_llm_data/dcformer_compare_experiments/vit/

TPU_NAME=llm-jax-v3-32-10
ZONE=us-east1-d
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b main https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis"
STEP=0

gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen14B --job_log_dir=gs://llm_base_models/qwen/14B/paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True | tee Qwen14BEval.step$STEP.log"



TPU_NAME=llm-jax-v4-32-10
ZONE=us-central2-b
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; gsutil -m cp -r  gs://llm_projects_us-central2/llm_base_models/qwen/14B/projects  ./"
STEP=0
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; sudo rm -f /tmp/libtpu_lockfile;sudo chmod +777 -R /tmp/tpu_logs/;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen14B --job_log_dir=gs://llm_projects_us-central2/llm_base_models/qwen/14B/paxml/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=True | tee Qwen14BEval.step$STEP.log"

# eval
TPU_NAME=llm-jax-v3-32-10
ZONE=us-east1-d
STEP=11000
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Qwen14BEval --job_log_dir=gs://llm_base_models/qwen/14B/paxml1127 2>&1 --enable_checkpoint_saving=False --eval_on_test=True | tee Qwen14BEval.step$STEP.log"

# install
TPU_NAME=llm-jax-v3-32-10
ZONE=us-east1-d
STEP=11000
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="/home/lishengping/miniconda3/bin/pip install google-cloud-storage"

gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="/home/lishengping/miniconda3/bin/pip install -c conda-forge jupyter_contrib_nbextensions"

conda install -c conda-forge jupyter_contrib_nbextensions


gcloud compute instances set-boot-disk l4-0 --boot-disk DEVICE_NAME=l4-0

gcloud compute instances reset l4-0 --boot-disk DEVICE_NAME=l4-0


TPU_NAME=llm-jax-v3-8-10
ZONE=us-east1-d
EXP=Llama7B
python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee L34_QP2048_Fscan2048_LMn_8192x1.log


TPU_NAME=llm-jax-v3-8-10
ZONE=us-central1-a
EXP=Llama7BMoe
cd /home/lishengping/;sudo rm -r projects/*; git clone -b main https://github.com/Lisennlp/paxml_praxis.git; mv paxml_praxis/*  projects/;sudo rm -r paxml_praxis
python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee openmoe_L20_E8_B1_M1x8x1_.Llama


TPU_NAME=llm-jax-v3-32-10
ZONE=us-east1-d
EXP=Llama7B
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; /home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee $EXP.log"


gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; gsutil -m cp -r  gs://llm_base_models/lsp_test/Llama7B/paxml gs://llm_base_models/lsp_test/Llama7B/praxis  projects/"


TPU_NAME=llm-jax-v3-64-10
ZONE=us-east1-d
EXP=Llama7v64
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; /home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee L48_C1_QP1024_Fn_LM1024_16k.log"


gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; gsutil -m cp -r  gs://llm_base_models/lsp_test/paxml gs://llm_base_models/lsp_test/praxis  projects/"

gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; /home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee L48_C1_QP1024_Fn_LM1024_16k.log"


export TFDS_DATA_DIR=gs://jax_llm_data/dcformer_compare_experiments/vit/test
python3 -m big_vision.tools.download_tfds_datasets imagenet_v2
python3 -m big_vision.tools.download_tfds_datasets cifar10


gcloud alpha compute tpus tpu-vm create llm-jax-v3-8-10 --zone us-east1-d --accelerator-type='v3-8' --version='v2-alpha' --scopes=https://www.googleapis.com/auth/cloud-platform


gcloud compute instances create instance-test \
    --machine-type n1-standard-8 \
    --zone us-east1-d \
    --boot-disk-size 200GB \
    --scopes https://www.googleapis.com/auth/cloud-platform


# imagenet2012
export TFDS_DATA_DIR=gs://jax_llm_data/dcformer_compare_experiments/vit/
WORKDIR=gs://jax_llm_data/dcformer_compare_experiments/vit/big_vision/`date '+%m-%d_%H%M'`
python -m big_vision.train --config big_vision/configs/bit_i1k.py  --workdir $WORKDIR


python -m big_vision.train --config big_vision/configs/vit_s16_i1k.py --workdir workdirs/`date '+%m-%d_%H%M'`



sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9
sudo rm -f /tmp/libtpu_lockfile
sudo chmod +777 -R /tmp/tpu_logs/


TPU_NAME=llm-jax-v4-8-10
ZONE=us-central2-b
WOKRDIR=gs://jax_llm_data/dcformer_compare_experiments/logs_self/wmt_256/
CODEDIR=/home/lishengping/projects/flax/examples/wmt
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; sudo rm -f /tmp/libtpu_lockfile;sudo chmod +777 -R /tmp/tpu_logs/; /home/lishengping/miniconda3/bin/python $CODEDIR/main.py --workdir=$WOKRDIR --config=$CODEDIR/configs/default.py $FLAGS| tee train.log"


TPU_NAME=llm-jax-v3-32-10
ZONE=us-east1-d
WOKRDIR=gs://jax_llm_data/dcformer_compare_experiments/logs_self/wmt_256/
CODEDIR=/home/lishengping/projects/flax/examples/wmt
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; sudo rm -f /tmp/libtpu_lockfile;sudo chmod +777 -R /tmp/tpu_logs/; /home/lishengping/miniconda3/bin/python $CODEDIR/main.py --workdir=$WOKRDIR --config=$CODEDIR/configs/default.py $FLAGS| tee train.log"


python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.Llama7B --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee L48_QP2048_Fn_LMn_16k.log
python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.PileDCSlimLlama7B8Kx1x512x1Win256_4K --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee L48_QP128_Fn_LM512_8k.log




TPU_NAME=llm-jax-v3-32-10
ZONE=us-central1-a
EXP=Llama7Bv32
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="/home/lishengping/miniconda3/bin/python -c 'import jax; print(jax.devices())'"

gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b main https://github.com/Lisennlp/paxml_praxis.git; mv paxml_praxis/*  projects/;sudo rm -r paxml_praxis"
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="killall main.py;sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; /home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee L48_QP2048_Fn_LMn_24k_B0.5_M1x16x2.log"



TPU_NAME=llm-jax-v4-16-10
ZONE=us-central2-b
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="cd /home/lishengping/;sudo rm -r projects/*; git clone -b main https://github.com/Lisennlp/paxml_praxis.git;mv paxml_praxis/*  projects/;rm -r paxml_praxis"
EXP=Llama7B
gcloud compute tpus tpu-vm ssh $TPU_NAME --zone=$ZONE --worker=all --command="sudo lsof -w /dev/accel0 |cut -c 9-14|awk 'NR>1 {print $1}'| xargs sudo kill -9; sudo rm -f /tmp/libtpu_lockfile;sudo chmod +777 -R /tmp/tpu_logs/;/home/lishengping/miniconda3/bin/python /home/lishengping/projects/paxml/paxml/main.py --exp=tasks.lm.params.c4.$EXP --job_log_dir=gs://llm_base_models/lsp_test/ 2>&1 --enable_checkpoint_saving=False --eval_on_test=False | tee test.log"



 func(*args, **kwargs)
  File "/home/lishengping/projects/paxml/paxml/main.py", line 582, in _main
    run(
  File "/home/lishengping/projects/praxis/praxis/py_utils.py", line 1051, in wrapper
    result = func(*args, **kwargs)
  File "/home/lishengping/projects/paxml/paxml/main.py", line 511, in run
    run_experiment(
  File "/home/lishengping/projects/praxis/praxis/py_utils.py", line 1051, in wrapper
    result = func(*args, **kwargs)
  File "/home/lishengping/projects/paxml/paxml/main.py", line 371, in run_experiment
    train.train_and_evaluate(
  File "/home/lishengping/projects/praxis/praxis/py_utils.py", line 1051, in wrapper
    result = func(*args, **kwargs)
  File "/home/lishengping/projects/paxml/paxml/train.py", line 319, in train_and_evaluate
    executor.start()
  File "/home/lishengping/projects/paxml/paxml/executors.py", line 278, in start
    _train_and_evaluate_common(
  File "/home/lishengping/projects/paxml/paxml/executors.py", line 463, in _train_and_evaluate_common
    program_output = train_program.run(partitioned_train_state, step_i)
  File "/home/lishengping/projects/praxis/praxis/py_utils.py", line 1051, in wrapper
    result = func(*args, **kwargs)
  File "/home/lishengping/projects/paxml/paxml/programs.py", line 305, in run
    model_inputs = self._partitioner.preprocess_inputs(
  File "/home/lishengping/projects/paxml/paxml/partitioning.py", line 925, in preprocess_inputs
    return input_pipeline.reshard_for_spmd(
  File "/home/lishengping/projects/praxis/praxis/base_input.py", line 347, in reshard_for_spmd
    return py_utils.make_array(arrays, global_shapes, global_mesh, pspecs)
  File "/home/lishengping/projects/praxis/praxis/py_utils.py", line 414, in make_array
    logging.info(f'local_mesh: {global_mesh.local_mesh}')
  File "/home/lishengping/miniconda3/lib/python3.10/site-packages/jax/_src/mesh.py", line 278, in local_mesh
    return self._local_mesh(xb.process_index())
  File "/home/lishengping/miniconda3/lib/python3.10/site-packages/jax/_src/mesh.py", line 281, in _local_mesh
    return _get_local_mesh(self, process_index)
  File "/home/lishengping/miniconda3/lib/python3.10/site-packages/jax/_src/mesh.py", line 119, in _get_local_mesh
    raise ValueError(
ValueError: When passing host local inputs to pjit or xmap, devices connected to a single host must form a contiguous subcube of the global device mesh
wandb: WARNING Ensure read and write access to run files dir: /home/lishengping/wandb/run-20240117_114811-nx14rx2l/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables