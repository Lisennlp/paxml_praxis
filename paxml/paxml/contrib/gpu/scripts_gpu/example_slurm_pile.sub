#!/bin/bash
#SBATCH -A example              # slurm account
#SBATCH -p partition            # slurm partition name
#SBATCH -N 8                    # number of nodes
#SBATCH -t 04:00:00             # wall time
#SBATCH -J "paxml:test"         # job name
#SBATCH --exclusive             # exclusive node access
#SBATCH --mem=0                 # all mem avail
#SBATCH --ntasks-per-node=8     # n tasks per machine (one task per gpu)
#SBATCH --overcommit            
#SBATCH --dependency=singleton  # only run one instance at a time
set -x

# coding=utf-8
# Copyright 2022 The Pax Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# File system and volume glue code
#-------------------------------------------------------------------------------
# << CHANGE ! >>
CONTAINER=<CONTAINER_NAME>

# << CHANGE ! >>
BASE_WORKSPACE_DIR=<PATH_TO_WORKSPACE> ## location to write logs and checkpoints to
BASE_TFDS_DATA_DIR=<PATH_TO_TFDS_DATA_DIR>
BASE_VOCAB_PATH=<PATH_TO_VOCAB>

# Default env variables for paths required by pax training scripts
WORKSPACE_DIR=/pax/paxml/workspace
TFDS_DATA_DIR=/pax/datasets/
GPT_VOCAB_PATH=/pax/vocab

# Add the pax/JAX specific mounts
MOUNTS="--container-mounts=$BASE_WORKSPACE_DIR:$WORKSPACE_DIR,$BASE_VOCAB_PATH:$GPT_VOCAB_PATH,$BASE_TFDS_DATA_DIR:/$TFDS_DATA_DIR"

# Add pax/JAX specific exports
EXPORTS="--export=ALL,TFDS_DATA_DIR=${TFDS_DATA_DIR},WORKSPACE_DIR=${WORKSPACE_DIR},GPT_VOCAB_PATH=${GPT_VOCAB_PATH}"
#-------------------------------------------------------------------------------

LOG_DIR_LOCAL='pile_126m'

# << INSERT SENTENCEPIECE MODEL NAME ! >>
read -r -d '' cmd <<EOF
echo "*******STARTING********" \
&& nvidia-smi \
&& bash /pax/paxml/paxml/contrib/gpu/scripts_gpu/run_pile_multinode.sh $TFDS_DATA_DIR ${GPT_VOCAB_PATH}/<NAME_OF_SPM_MODEL> 'workspace/${LOG_DIR_LOCAL}'
EOF

# create run specific output directory for ease of analysis
mkdir -p "${BASE_WORKSPACE_DIR}/outputs/multinode/126m_pile"

# redirect both stdout and stderr in the same file for ease of analysis
OUTFILE="${BASE_WORKSPACE_DIR}/outputs/multinode/126m_pile/output-%j-%n-%t.txt"

echo $cmd
srun -o $OUTFILE -e $OUTFILE --container-image="$CONTAINER" $MOUNTS $EXPORTS bash -c "${cmd}"
set +x


